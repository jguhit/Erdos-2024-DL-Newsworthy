{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Erdos-2024-DL-Newsworthy/sentiment_modified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu_index = 1  # Change to 1 if you want to use the second GPU\n",
    "#device = torch.device(f\"cuda:{gpu_index}\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seed=23):\n",
    "    dataset_openai = load_dataset('csv', data_files='news_openai_final.csv')\n",
    "\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_val_test_split = dataset_openai['train'].train_test_split(test_size=0.2, seed=seed)\n",
    "    train_val_split = train_val_test_split['train'].train_test_split(test_size=0.25, seed=seed)\n",
    "\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_val_split['train'].shuffle(seed=seed),  # 60% of the original data\n",
    "        'validation': train_val_split['test'].shuffle(seed=seed),  # 20% of the original data\n",
    "        'test': train_val_test_split['test'].shuffle(seed=seed),  # 20% of the original data\n",
    "    })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Publishing Time', 'Ticker', 'Sector', 'Source', 'Headline', 'Text', 'openai_sentiment', 'openai_score'],\n",
       "    num_rows: 12741\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = prepare_data()\n",
    "dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sentiment_model import SentimentModel\n",
    "from SentimentDataModule import SentimentDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate without fine-tuning roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_roberta = SentimentDataModule(dataset['train'], dataset['validation'], 8,  512)\n",
    "data_module_roberta.setup()\n",
    "val_loader_roberta = data_module_roberta.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: -1, 1: 0, 2: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions_roberta = 0\n",
    "total_predictions_roberta = 0\n",
    "all_predictions_roberta = []\n",
    "all_labels_roberta = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_loader_roberta:\n",
    "        #print(batch)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Compute predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        predictions_mapped = torch.tensor([label_map[pred.item()] for pred in predictions]).to(device)\n",
    "        labels_mapped = torch.tensor([label_map[label.item()] for label in labels]).to(device)\n",
    "\n",
    "        correct_predictions_roberta += (predictions_mapped == labels_mapped).sum().item()\n",
    "        total_predictions_roberta += labels_mapped.size(0)\n",
    "        all_predictions_roberta.extend(predictions_mapped.cpu().numpy())\n",
    "        all_labels_roberta.extend(labels_mapped.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Roberta: 0.5403\n",
      "Classification Report Roberta:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Class -1       0.00      0.00      0.00      2784\n",
      "     Class 0       0.00      0.00      0.00      3683\n",
      "     Class 1       0.54      1.00      0.70      7602\n",
      "\n",
      "    accuracy                           0.54     14069\n",
      "   macro avg       0.18      0.33      0.23     14069\n",
      "weighted avg       0.29      0.54      0.38     14069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/data19/guhitj/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/atlas/data19/guhitj/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/atlas/data19/guhitj/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_roberta = correct_predictions_roberta / total_predictions_roberta\n",
    "report_roberta = classification_report(all_labels_roberta, all_predictions_roberta, target_names=['Class -1', 'Class 0', 'Class 1'])\n",
    "\n",
    "print(f'Accuracy Roberta: {accuracy_roberta:.4f}')\n",
    "print(f'Classification Report Roberta:\\n{report_roberta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating with finetuned roberta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/data19/guhitj/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/lustre/umt3/user/guhitj/Erdos_bootcamp/Deeplearning/Project/Results/NewRun/checkpoints/Run_15_20240822-181659_FullRun30EFineTune/epoch=07-val_loss=0.34250.ckpt'\n",
    "model_finetuned = SentimentModel.load_from_checkpoint(checkpoint_path)\n",
    "model_finetuned.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_finetuned = model_finetuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_finetuned = SentimentDataModule(dataset['train'], dataset['validation'], 8,  512)\n",
    "data_module_finetuned.setup()\n",
    "val_loader_finetuned = data_module_finetuned.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions_finetuned = 0\n",
    "total_predictions_finetuned = 0\n",
    "all_predictions_finetuned = []\n",
    "all_labels_finetuned = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8495,  0.9794, -0.2926],\n",
      "        [-2.8407,  0.0609,  3.4937],\n",
      "        [-3.1853,  0.3962,  2.7780],\n",
      "        [-2.7150,  0.0652,  3.2664],\n",
      "        [-2.5927, -0.9768,  4.7615],\n",
      "        [-0.6470,  2.2161, -1.6748],\n",
      "        [-3.2770, -0.0628,  3.5134],\n",
      "        [-3.5099,  0.0594,  3.9389]], device='cuda:0')\n",
      "tensor([[-3.0354, -0.9553,  4.5509],\n",
      "        [-1.8296,  2.2671, -0.7282],\n",
      "        [-0.1401,  0.2205,  0.0656],\n",
      "        [-1.9395,  1.5582,  0.0409],\n",
      "        [-2.4522, -0.9828,  4.3216],\n",
      "        [-2.2371, -1.1828,  4.3541],\n",
      "        [ 1.8432,  0.7105, -2.1488],\n",
      "        [-0.9883,  2.2971, -1.5327]], device='cuda:0')\n",
      "tensor([[-0.8131,  3.0554, -2.4566],\n",
      "        [-3.2004,  0.1361,  3.2120],\n",
      "        [-3.0487, -0.8143,  4.5641],\n",
      "        [-2.7971, -0.5153,  3.5457],\n",
      "        [-2.9204, -0.5924,  4.2385],\n",
      "        [-2.8638,  0.1758,  3.5441],\n",
      "        [-3.8170,  1.2761,  2.3542],\n",
      "        [ 1.9802,  0.5075, -2.6186]], device='cuda:0')\n",
      "tensor([[-2.8255, -0.7810,  4.4605],\n",
      "        [-3.2858,  1.0930,  1.9131],\n",
      "        [-2.9068, -1.3206,  5.2362],\n",
      "        [-3.5233, -0.4102,  3.9072],\n",
      "        [-2.4125,  0.4682,  1.4942],\n",
      "        [-3.5220, -0.8435,  4.7829],\n",
      "        [-0.3951,  1.2335, -1.0283],\n",
      "        [-3.1640, -0.4835,  4.2598]], device='cuda:0')\n",
      "tensor([[-2.4796,  0.2823,  1.8909],\n",
      "        [-0.6842,  1.5083, -1.1664],\n",
      "        [ 3.8882, -0.7320, -3.0844],\n",
      "        [ 0.4676,  1.3064, -1.9814],\n",
      "        [ 0.4317,  1.6310, -2.0369],\n",
      "        [ 0.2912,  1.1592, -1.3352],\n",
      "        [-3.5495,  0.7881,  2.8611],\n",
      "        [-1.8137,  0.6704,  1.3806]], device='cuda:0')\n",
      "tensor([[ 0.6058,  0.4752, -0.9988],\n",
      "        [ 2.9710,  0.6646, -3.1734],\n",
      "        [-2.2985,  0.2335,  2.3098],\n",
      "        [-0.0716,  0.8990, -0.7927],\n",
      "        [-2.6796,  1.2390,  0.9923],\n",
      "        [-2.7379, -1.4084,  5.3515],\n",
      "        [ 2.7675,  0.1265, -2.2562],\n",
      "        [ 2.4501,  0.1375, -2.0396]], device='cuda:0')\n",
      "tensor([[-0.5022,  0.7796, -0.3658],\n",
      "        [-1.5886, -0.0783,  1.8868],\n",
      "        [-1.7786,  1.3210,  0.3671],\n",
      "        [ 4.3824, -1.4464, -2.4300],\n",
      "        [-2.7356, -0.9812,  4.6236],\n",
      "        [-2.5824, -1.0569,  5.0135],\n",
      "        [ 2.1188,  0.1413, -2.0511],\n",
      "        [-2.8682,  0.8269,  2.0504]], device='cuda:0')\n",
      "tensor([[-2.6983, -0.4817,  3.6420],\n",
      "        [ 4.1474, -1.1539, -3.2918],\n",
      "        [ 1.3723,  0.8973, -2.2449],\n",
      "        [-2.9950,  0.0414,  3.3744],\n",
      "        [-3.0800, -0.8286,  4.5631],\n",
      "        [ 2.8379,  0.7340, -3.4537],\n",
      "        [-2.2112, -1.4861,  4.7355],\n",
      "        [-2.1897, -1.3043,  4.7494]], device='cuda:0')\n",
      "tensor([[ 1.9292,  0.2319, -1.8277],\n",
      "        [ 0.6445,  1.8936, -2.6474],\n",
      "        [-2.2160,  1.9331, -0.0353],\n",
      "        [-1.9635, -1.2653,  4.8708],\n",
      "        [-2.3476,  1.5027,  0.3617],\n",
      "        [-2.8414, -0.5437,  4.3705],\n",
      "        [-3.2806, -0.1823,  4.4250],\n",
      "        [-2.5841, -0.7624,  4.3413]], device='cuda:0')\n",
      "tensor([[ 4.8984, -1.7134, -3.2518],\n",
      "        [-2.1189,  0.3484,  2.2020],\n",
      "        [-2.8040,  3.0937, -0.6646],\n",
      "        [ 2.4215,  0.1037, -2.2742],\n",
      "        [-2.8004, -0.6223,  4.0214],\n",
      "        [ 4.6390, -1.0940, -3.3319],\n",
      "        [-2.1683,  1.5905,  0.3709],\n",
      "        [ 0.4199,  1.0525, -1.1537]], device='cuda:0')\n",
      "tensor([[-4.1415,  2.3891,  1.1879],\n",
      "        [-3.4824, -0.9836,  5.1687],\n",
      "        [-2.5619, -1.2920,  5.0691],\n",
      "        [-2.9742, -0.7436,  4.5380],\n",
      "        [-3.1106, -0.8236,  5.0348],\n",
      "        [-0.3498,  0.6229, -0.1525],\n",
      "        [ 0.7572,  0.9346, -1.6690],\n",
      "        [-3.0266, -1.0209,  4.9190]], device='cuda:0')\n",
      "tensor([[-3.3144, -0.5850,  4.7990],\n",
      "        [-2.3954,  0.2575,  2.5374],\n",
      "        [-2.4229,  0.4125,  2.5219],\n",
      "        [ 3.2738, -0.2557, -2.6538],\n",
      "        [-0.1969,  2.3554, -2.1152],\n",
      "        [-2.4062, -0.8757,  4.7587],\n",
      "        [-3.1253,  0.8747,  2.4421],\n",
      "        [ 1.3684,  0.8448, -2.1169]], device='cuda:0')\n",
      "tensor([[ 3.9873e+00, -6.7332e-01, -3.4899e+00],\n",
      "        [-1.9321e+00,  1.0892e+00,  5.3834e-01],\n",
      "        [-1.9431e+00, -3.0524e-01,  3.2409e+00],\n",
      "        [ 3.8880e+00, -3.6485e-01, -3.1289e+00],\n",
      "        [-3.4452e+00,  2.1382e-03,  3.7224e+00],\n",
      "        [-3.3217e+00,  3.8389e+00, -1.4599e+00],\n",
      "        [-2.4814e+00,  1.8697e+00,  1.6122e-01],\n",
      "        [-1.6810e+00,  2.2351e+00, -1.2540e+00]], device='cuda:0')\n",
      "tensor([[ 0.3268,  0.3660, -0.5998],\n",
      "        [-1.4491,  1.5830, -0.1434],\n",
      "        [-3.4233, -0.3168,  4.0112],\n",
      "        [-3.1841, -0.9929,  4.9214],\n",
      "        [-0.8596,  1.0056, -0.1439],\n",
      "        [-2.4277, -0.6759,  4.1659],\n",
      "        [-2.1924, -0.1548,  2.5954],\n",
      "        [-1.5919,  2.7591, -1.6098]], device='cuda:0')\n",
      "tensor([[-2.6708, -1.0288,  4.7537],\n",
      "        [-0.8542,  2.0765, -1.7179],\n",
      "        [-2.5299,  4.2797, -2.5687],\n",
      "        [-1.7947,  2.0130, -0.4226],\n",
      "        [ 4.8497, -1.6938, -3.8992],\n",
      "        [-2.9389, -0.4448,  4.0723],\n",
      "        [-2.4434, -0.8043,  4.3165],\n",
      "        [-3.2638, -1.1572,  5.1873]], device='cuda:0')\n",
      "tensor([[-0.1199,  1.9061, -1.5928],\n",
      "        [-0.7245,  1.0697, -0.3447],\n",
      "        [-2.2508, -0.2796,  2.9056],\n",
      "        [-0.2819,  1.7133, -1.6490],\n",
      "        [-2.8916, -0.2122,  3.6929],\n",
      "        [-2.4396,  4.2279, -2.1667],\n",
      "        [-2.5140,  0.6432,  1.5206],\n",
      "        [-2.4548,  0.9453,  1.4882]], device='cuda:0')\n",
      "tensor([[-2.8019,  0.3976,  2.8455],\n",
      "        [-1.8140,  1.8350, -0.3949],\n",
      "        [-2.6680,  0.6084,  2.1856],\n",
      "        [ 3.6715, -0.6899, -3.3273],\n",
      "        [-2.6324,  0.2010,  3.1149],\n",
      "        [-2.8022, -1.3785,  4.8931],\n",
      "        [-2.7928,  3.0235, -0.9069],\n",
      "        [-2.9406,  0.2866,  2.5020]], device='cuda:0')\n",
      "tensor([[ 1.0825,  2.2697, -3.3606],\n",
      "        [-3.3798,  1.1909,  2.2677],\n",
      "        [-2.0731,  0.4705,  1.7404],\n",
      "        [ 3.9421, -0.1861, -3.2709],\n",
      "        [ 1.6340,  1.2522, -2.4537],\n",
      "        [-1.5831, -0.1375,  2.2387],\n",
      "        [-3.5789,  3.1130, -0.5577],\n",
      "        [-2.9831, -0.7518,  4.7228]], device='cuda:0')\n",
      "tensor([[-2.5959,  0.3393,  2.4204],\n",
      "        [ 0.9782,  1.1141, -1.7878],\n",
      "        [-1.6383,  0.3946,  1.1399],\n",
      "        [-2.3873,  4.2328, -2.5314],\n",
      "        [-4.2358,  2.8669,  0.7041],\n",
      "        [-3.1773, -0.5414,  4.2167],\n",
      "        [-3.9033,  0.6981,  3.3317],\n",
      "        [-3.0716, -0.4558,  4.1315]], device='cuda:0')\n",
      "tensor([[-1.8130,  1.3188,  0.3407],\n",
      "        [ 4.7951, -1.4551, -3.6315],\n",
      "        [-0.8282,  1.0717, -0.2025],\n",
      "        [-2.9092, -1.3757,  5.3965],\n",
      "        [-0.9408,  1.5703, -0.7858],\n",
      "        [-2.5095,  1.0963,  1.1635],\n",
      "        [-1.2096,  1.3210, -0.1427],\n",
      "        [-2.6556, -0.6252,  4.4618]], device='cuda:0')\n",
      "tensor([[-2.4982, -0.0244,  2.7396],\n",
      "        [-2.9120, -0.9508,  4.6739],\n",
      "        [-2.0449,  1.3035,  0.4774],\n",
      "        [ 1.0600,  1.6328, -2.8659],\n",
      "        [-2.7365, -1.2765,  5.2151],\n",
      "        [-1.9736,  3.0407, -1.4674],\n",
      "        [-2.2250, -0.9571,  4.5051],\n",
      "        [-3.2728, -0.2718,  4.0656]], device='cuda:0')\n",
      "tensor([[-1.2575e+00,  1.2979e+00, -2.0001e-03],\n",
      "        [-2.5656e+00,  2.3739e+00, -1.6639e-01],\n",
      "        [-2.6086e+00, -1.1256e+00,  4.4446e+00],\n",
      "        [-2.5222e+00, -9.8996e-02,  3.0831e+00],\n",
      "        [-1.8455e+00,  2.0485e+00, -6.6325e-01],\n",
      "        [-3.5431e+00,  3.6668e+00, -8.9174e-01],\n",
      "        [ 3.3451e+00, -6.7512e-01, -2.3449e+00],\n",
      "        [-2.0865e+00, -6.3795e-01,  3.7460e+00]], device='cuda:0')\n",
      "tensor([[-1.3001,  2.3651, -1.1312],\n",
      "        [-2.3338, -0.7718,  3.6304],\n",
      "        [-1.5407,  1.1424,  0.2264],\n",
      "        [-3.1527, -1.1642,  5.3593],\n",
      "        [-2.4734,  3.0370, -1.1679],\n",
      "        [-0.4346,  2.2960, -1.7913],\n",
      "        [-1.8172,  1.4501,  0.2287],\n",
      "        [-2.1915,  1.0442,  1.0294]], device='cuda:0')\n",
      "tensor([[-3.6182,  0.2555,  3.0966],\n",
      "        [-2.4512,  4.2601, -2.6096],\n",
      "        [-3.0131, -0.4313,  3.9040],\n",
      "        [-2.7429, -1.1329,  4.8983],\n",
      "        [-0.7308,  1.5938, -0.8901],\n",
      "        [-0.0792,  2.6464, -2.5731],\n",
      "        [-3.2527,  2.0502,  0.9658],\n",
      "        [-3.0074, -0.4976,  3.9142]], device='cuda:0')\n",
      "tensor([[-2.3511,  0.3887,  1.9202],\n",
      "        [ 3.3274,  0.5644, -3.9112],\n",
      "        [-0.4562,  1.8510, -1.3955],\n",
      "        [-2.3707,  0.6458,  2.0801],\n",
      "        [-3.5350,  0.3429,  3.4364],\n",
      "        [ 3.9166, -0.5388, -3.0009],\n",
      "        [-2.2416,  0.4794,  1.5025],\n",
      "        [-3.6473,  3.1823, -0.4583]], device='cuda:0')\n",
      "tensor([[-0.2901,  1.5506, -1.4372],\n",
      "        [-0.0638,  1.2053, -1.0793],\n",
      "        [ 0.9690,  1.0124, -2.0210],\n",
      "        [-3.6776, -0.5871,  4.9539],\n",
      "        [-2.5045, -0.3358,  3.7471],\n",
      "        [ 0.2019,  1.1914, -1.1700],\n",
      "        [-3.1917,  0.1312,  3.5238],\n",
      "        [-0.8384,  0.6428,  0.2474]], device='cuda:0')\n",
      "tensor([[-2.8212, -0.9507,  4.5109],\n",
      "        [ 4.4186, -0.8452, -3.1566],\n",
      "        [-3.0716, -0.6734,  4.4477],\n",
      "        [-3.3300, -1.0308,  5.4496],\n",
      "        [-2.0053,  0.0943,  2.1477],\n",
      "        [-3.3625,  4.0643, -1.3658],\n",
      "        [-3.4291,  0.4389,  2.9379],\n",
      "        [ 1.2412,  1.2919, -2.6733]], device='cuda:0')\n",
      "tensor([[ 1.5193,  1.3152, -2.8316],\n",
      "        [ 4.7796, -0.9692, -3.6383],\n",
      "        [-2.7204,  3.0766, -0.7252],\n",
      "        [-2.7249,  1.8346,  0.3227],\n",
      "        [-3.1202,  0.2374,  2.8615],\n",
      "        [-3.8943,  0.0465,  4.4229],\n",
      "        [-3.1638, -0.8652,  4.9326],\n",
      "        [-2.9392, -0.9179,  5.0190]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model_finetuned(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m      9\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Compute predictions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/torch/_tensor.py:463\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    460\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    461\u001b[0m     )\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/torch/_tensor_str.py:698\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    697\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/torch/_tensor_str.py:618\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    616\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    617\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 618\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    621\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/torch/_tensor_str.py:350\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/micromamba/envs/erdos_2024_dl_newsworthy/lib/python3.11/site-packages/torch/_tensor_str.py:138\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_loader_finetuned:\n",
    "        #print(batch)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model_finetuned(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[1]\n",
    "        print(logits)\n",
    "      \n",
    "        # Compute predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        predictions_mapped = torch.tensor([label_map[pred.item()] for pred in predictions]).to(device)\n",
    "        labels_mapped = torch.tensor([label_map[label.item()] for label in labels]).to(device)\n",
    "\n",
    "        correct_predictions_finetuned += (predictions_mapped == labels_mapped).sum().item()\n",
    "        total_predictions_finetuned += labels_mapped.size(0)\n",
    "        all_predictions_finetuned.extend(predictions_mapped.cpu().numpy())\n",
    "        all_labels_finetuned.extend(labels_mapped.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Roberta: 0.8804\n",
      "Classification Report Roberta:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Class -1       0.87      0.89      0.88      2535\n",
      "     Class 0       0.75      0.83      0.79      3324\n",
      "     Class 1       0.96      0.90      0.93      6882\n",
      "\n",
      "    accuracy                           0.88     12741\n",
      "   macro avg       0.86      0.87      0.87     12741\n",
      "weighted avg       0.89      0.88      0.88     12741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_finetuned = correct_predictions_finetuned / total_predictions_finetuned\n",
    "report_finetuned = classification_report(all_labels_finetuned, all_predictions_finetuned, target_names=['Class -1', 'Class 0', 'Class 1'])\n",
    "\n",
    "print(f'Accuracy Roberta: {accuracy_finetuned:.4f}')\n",
    "print(f'Classification Report Roberta:\\n{report_finetuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_file = 'news_openai_final.csv'\n",
    "df = pd.read_csv(news_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentimentDataModule_all import SentimentDataModule_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_fullDS = SentimentDataModule_all(dataset, 8,  512)\n",
    "data_module_fullDS.setup()\n",
    "data_loader_fullDS = data_module_fullDS.dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions_fullDS = 0\n",
    "total_predictions_fullDS = 0\n",
    "all_predictions_fullDS = []\n",
    "all_labels_fullDS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in data_loader_fullDS:\n",
    "        #print(batch)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model_finetuned(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[1]\n",
    "        \n",
    "        # Compute predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        predictions_mapped = torch.tensor([label_map[pred.item()] for pred in predictions]).to(device)\n",
    "        labels_mapped = torch.tensor([label_map[label.item()] for label in labels]).to(device)\n",
    "\n",
    "        correct_predictions_fullDS += (predictions_mapped == labels_mapped).sum().item()\n",
    "        total_predictions_fullDS += labels_mapped.size(0)\n",
    "        all_predictions_fullDS.extend(predictions_mapped.cpu().numpy())\n",
    "        all_labels_fullDS.extend(labels_mapped.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Roberta: 0.8841\n",
      "Classification Report Roberta:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Class -1       0.88      0.89      0.88     12912\n",
      "     Class 0       0.75      0.83      0.79     16501\n",
      "     Class 1       0.96      0.90      0.93     34290\n",
      "\n",
      "    accuracy                           0.88     63703\n",
      "   macro avg       0.86      0.87      0.87     63703\n",
      "weighted avg       0.89      0.88      0.88     63703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_fullDS = correct_predictions_fullDS / total_predictions_fullDS\n",
    "report_fullDS = classification_report(all_labels_fullDS, all_predictions_fullDS, target_names=['Class -1', 'Class 0', 'Class 1'])\n",
    "\n",
    "print(f'Accuracy Roberta: {accuracy_fullDS:.4f}')\n",
    "print(f'Classification Report Roberta:\\n{report_fullDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_predictions_fullDS) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['finetune_roberta_sentiment'] = all_predictions_fullDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['finetune_roberta_sentiment'] = df['finetune_roberta_sentiment'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publishing Time</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>openai_sentiment</th>\n",
       "      <th>openai_score</th>\n",
       "      <th>finetune_roberta_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-15 10:46:42+00:00</td>\n",
       "      <td>WFC</td>\n",
       "      <td>Finance</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Did Wells Fargo CEO Tim Sloan Earn His $1 Mill...</td>\n",
       "      <td>We learned this week that the scandal-plagued ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-15 10:47:26+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Don't Underestimate Apple's iPhone Business</td>\n",
       "      <td>The segment is an invaluable asset to Apple's ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-15 11:33:00+00:00</td>\n",
       "      <td>MA</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>A Closer Look At Mastercard's Key Value Drivers</td>\n",
       "      <td>Mastercard has consistently beat street estima...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-15 11:52:45+00:00</td>\n",
       "      <td>BAC</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>Jim Cramer Gives His Opinion On Bank Of Americ...</td>\n",
       "      <td>On CNBC's \"Mad Money Lightning Round\", Jim Cra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-15 13:29:39+00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>Uber And Waymo Seeking Outside Funding For Aut...</td>\n",
       "      <td>Commercially viable autonomous vehicle (AV) te...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-03-15 15:38:26+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>Amazon Wins Another Bull After KeyBanc Upgrade...</td>\n",
       "      <td>Amazon.com, Inc. accelerated its profitability...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-03-15 16:15:59+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Market Watch</td>\n",
       "      <td>Amazon's stock jumps after KeyBanc upgrade mak...</td>\n",
       "      <td>Shares of Amazon.com Inc. jumped 1.4% in prema...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-03-15 16:36:05+00:00</td>\n",
       "      <td>JPM</td>\n",
       "      <td>Finance</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Why Warren Buffett Thinks JPMorgan's Stock Cou...</td>\n",
       "      <td>The billionaire investor recently revealed his...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-15 18:07:30+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Market Watch</td>\n",
       "      <td>The Ratings Game: Amazon stock gains after Key...</td>\n",
       "      <td>It’s now unanimous—100% of the analysts survey...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-03-15 18:14:02+00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Experimental Google Maps feature puts arrows o...</td>\n",
       "      <td>CNBC tested Google Maps' new augmented reality...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-03-15 18:21:02+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Amazon is introducing private investors to hig...</td>\n",
       "      <td>Amazon Web Services has close ties to the star...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-03-15 19:16:44+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Apple's new streaming service seeks Oscar glory</td>\n",
       "      <td>Apple is reportedly hiring strategists to help...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-03-15 19:31:03+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Amazon's focus on boosting profits could raise...</td>\n",
       "      <td>Closing pop-up stores, pushing the grocery bus...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-03-15 19:34:10+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Microsoft says tech firm that Beijing allegedl...</td>\n",
       "      <td>SenseNets, a Chinese company that makes facial...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-03-15 19:38:08+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Amazon.com Stock Upgraded: What You Need to Know</td>\n",
       "      <td>One analyst thinks the tech giant is programmi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-03-15 19:40:00+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Apple Just Scored the $1 Billion It Was Asking...</td>\n",
       "      <td>But it won't be able to collect quite yet.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-03-16 00:33:45+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Amazon takes another step into the medical spa...</td>\n",
       "      <td>Health experts say it's a smart move for Amazo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-03-16 00:43:09+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Investors Business Daily</td>\n",
       "      <td>Why Amazon May Be Pivoting Toward Accelerating...</td>\n",
       "      <td>Amazon stock rose Friday as the e-commerce gia...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-03-16 14:01:03+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>24/7 Wall Street</td>\n",
       "      <td>Amazon May End Up With Only One Headquarters —...</td>\n",
       "      <td>The media has covered the chronicle of how Ama...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-03-16 14:06:34+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Amazon's 2nd headquarters faces new blocks in ...</td>\n",
       "      <td>Amazon in February abruptly scrapped plans to ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Publishing Time Ticker      Sector                    Source  \\\n",
       "0   2019-03-15 10:46:42+00:00    WFC     Finance           The Motley Fool   \n",
       "1   2019-03-15 10:47:26+00:00   AAPL  Technology           The Motley Fool   \n",
       "2   2019-03-15 11:33:00+00:00     MA     Finance                    Forbes   \n",
       "3   2019-03-15 11:52:45+00:00    BAC     Finance                  Benzinga   \n",
       "4   2019-03-15 13:29:39+00:00  GOOGL  Technology                  Benzinga   \n",
       "5   2019-03-15 15:38:26+00:00   AMZN  Technology                  Benzinga   \n",
       "6   2019-03-15 16:15:59+00:00   AMZN  Technology              Market Watch   \n",
       "7   2019-03-15 16:36:05+00:00    JPM     Finance           The Motley Fool   \n",
       "8   2019-03-15 18:07:30+00:00   AMZN  Technology              Market Watch   \n",
       "9   2019-03-15 18:14:02+00:00  GOOGL  Technology                      CNBC   \n",
       "10  2019-03-15 18:21:02+00:00   AMZN  Technology                      CNBC   \n",
       "11  2019-03-15 19:16:44+00:00   AAPL  Technology                      CNBC   \n",
       "12  2019-03-15 19:31:03+00:00   AMZN  Technology                      CNBC   \n",
       "13  2019-03-15 19:34:10+00:00   MSFT  Technology                      CNBC   \n",
       "14  2019-03-15 19:38:08+00:00   AMZN  Technology           The Motley Fool   \n",
       "15  2019-03-15 19:40:00+00:00   AAPL  Technology           The Motley Fool   \n",
       "16  2019-03-16 00:33:45+00:00   AMZN  Technology                      CNBC   \n",
       "17  2019-03-16 00:43:09+00:00   AMZN  Technology  Investors Business Daily   \n",
       "18  2019-03-16 14:01:03+00:00   AMZN  Technology          24/7 Wall Street   \n",
       "19  2019-03-16 14:06:34+00:00   AMZN  Technology                      CNBC   \n",
       "\n",
       "                                             Headline  \\\n",
       "0   Did Wells Fargo CEO Tim Sloan Earn His $1 Mill...   \n",
       "1         Don't Underestimate Apple's iPhone Business   \n",
       "2     A Closer Look At Mastercard's Key Value Drivers   \n",
       "3   Jim Cramer Gives His Opinion On Bank Of Americ...   \n",
       "4   Uber And Waymo Seeking Outside Funding For Aut...   \n",
       "5   Amazon Wins Another Bull After KeyBanc Upgrade...   \n",
       "6   Amazon's stock jumps after KeyBanc upgrade mak...   \n",
       "7   Why Warren Buffett Thinks JPMorgan's Stock Cou...   \n",
       "8   The Ratings Game: Amazon stock gains after Key...   \n",
       "9   Experimental Google Maps feature puts arrows o...   \n",
       "10  Amazon is introducing private investors to hig...   \n",
       "11    Apple's new streaming service seeks Oscar glory   \n",
       "12  Amazon's focus on boosting profits could raise...   \n",
       "13  Microsoft says tech firm that Beijing allegedl...   \n",
       "14   Amazon.com Stock Upgraded: What You Need to Know   \n",
       "15  Apple Just Scored the $1 Billion It Was Asking...   \n",
       "16  Amazon takes another step into the medical spa...   \n",
       "17  Why Amazon May Be Pivoting Toward Accelerating...   \n",
       "18  Amazon May End Up With Only One Headquarters —...   \n",
       "19  Amazon's 2nd headquarters faces new blocks in ...   \n",
       "\n",
       "                                                 Text  openai_sentiment  \\\n",
       "0   We learned this week that the scandal-plagued ...              -1.0   \n",
       "1   The segment is an invaluable asset to Apple's ...               1.0   \n",
       "2   Mastercard has consistently beat street estima...               1.0   \n",
       "3   On CNBC's \"Mad Money Lightning Round\", Jim Cra...               1.0   \n",
       "4   Commercially viable autonomous vehicle (AV) te...               0.0   \n",
       "5   Amazon.com, Inc. accelerated its profitability...               1.0   \n",
       "6   Shares of Amazon.com Inc. jumped 1.4% in prema...               1.0   \n",
       "7   The billionaire investor recently revealed his...               1.0   \n",
       "8   It’s now unanimous—100% of the analysts survey...               0.0   \n",
       "9   CNBC tested Google Maps' new augmented reality...               1.0   \n",
       "10  Amazon Web Services has close ties to the star...               1.0   \n",
       "11  Apple is reportedly hiring strategists to help...               1.0   \n",
       "12  Closing pop-up stores, pushing the grocery bus...               1.0   \n",
       "13  SenseNets, a Chinese company that makes facial...              -1.0   \n",
       "14  One analyst thinks the tech giant is programmi...               1.0   \n",
       "15         But it won't be able to collect quite yet.               0.0   \n",
       "16  Health experts say it's a smart move for Amazo...               1.0   \n",
       "17  Amazon stock rose Friday as the e-commerce gia...               1.0   \n",
       "18  The media has covered the chronicle of how Ama...               0.0   \n",
       "19  Amazon in February abruptly scrapped plans to ...              -1.0   \n",
       "\n",
       "    openai_score  finetune_roberta_sentiment  \n",
       "0          -0.50                         0.0  \n",
       "1           0.75                         1.0  \n",
       "2           0.80                         1.0  \n",
       "3           0.50                        -1.0  \n",
       "4           0.10                         0.0  \n",
       "5           0.75                         1.0  \n",
       "6           0.80                         1.0  \n",
       "7           0.75                         1.0  \n",
       "8           0.10                         1.0  \n",
       "9           0.75                         1.0  \n",
       "10          0.75                         1.0  \n",
       "11          0.75                         1.0  \n",
       "12          0.80                         1.0  \n",
       "13         -0.80                        -1.0  \n",
       "14          0.80                         1.0  \n",
       "15          0.00                         0.0  \n",
       "16          0.75                         1.0  \n",
       "17          0.75                         1.0  \n",
       "18          0.00                         0.0  \n",
       "19         -0.50                        -1.0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = 'news_finetuned_roberta.csv'  # Replace with your desired output path\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
